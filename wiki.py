# -*- coding: utf-8 -*-
"""wiki.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X5bqRyTUUnlKkc4MnAyZpHFIGSa18hnX
"""

!pip install scrapy

!scrapy startproject  pedia

# Commented out IPython magic to ensure Python compatibility.
# %cd pedia/pedia/spiders/

!scrapy genspider pedi https://www.wikipedia.org/

# Commented out IPython magic to ensure Python compatibility.
# %%writefile pedi.py
# import scrapy
# 
# class PediSpider(scrapy.Spider):
#     name = "pedi"
#     allowed_domains = ["www.wikipedia.org"]
#     start_urls = ["https://www.wikipedia.org/"]
# 
#     def parse(self, response):
#         posts=response.css('div.other-project')
#         print(len(posts))
#         for post in posts:
#           yield{
#             'title':post.css('a.other-project-link div.other-project-text span.other-project-title.jsl10n::text').get(),
#             'text':post.css('a.other-project-link div.other-project-text span.other-project-tagline.jsl10n::text').get()
# 
# 
#         }

!scrapy crawl pedi -o p_data.json

import json

with open('p_data.json','r') as file:
  data=json.load(file)

print(len(data))

first_post=data[0]
print(f"title: {first_post['title']}")
print(f":text {first_post['text']}")